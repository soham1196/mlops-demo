{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "![Impressions](https://PixelServer20190423114238.azurewebsites.net/api/impressions/NotebookVM/tutorials/quickstart-ci/AzureMLin10mins.png)"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train and deploy a model in Azure Machine Learning\n",
        "\n",
        "\n",
        "We will follow the following steps:\n",
        "- Create the scripts for Data Extraction and converting it for model training and serving/prediction pipeline\n",
        "- Create the script to build model and save the model and version control\n",
        "- Create the script to use the saved model and do the prediction\n",
        "- Create scripts to validate the models\n",
        "- Create scripts to monitor the model performance\n",
        "- Continuous Integration and Deployment scripts using open source platforms of your choice\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd \n",
        "import numpy as np\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1630358240526
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Data\n",
        "\n",
        "Dataset: https://www.kaggle.com/olistbr/marketing-funnel-olist\n",
        "\n",
        "\n",
        "This dataset was generously provided by Olist, the largest department store in Brazilian marketplaces. Olist connects small businesses from all over Brazil to channels without hassle and with a single contract. Those merchants are able to sell their products through the Olist Store and ship them directly to the customers using Olist logistics partners. See more on our website: www.olist.com\n",
        "\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# azureml-core of version 1.0.72 or higher is required\n",
        "# azureml-dataprep[pandas] of version 1.1.34 or higher is required\n",
        "from azureml.core import Workspace, Dataset\n",
        "\n",
        "subscription_id = '71b2b08a-790d-402f-9800-fa9ad29fcb60'\n",
        "resource_group = 'rg_sm'\n",
        "workspace_name = 'SM1196'\n",
        "\n",
        "workspace = Workspace(subscription_id, resource_group, workspace_name)\n",
        "\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1630358240863
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define functions for data preparation"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Load data\n",
        "def load_data(path):\n",
        "    df = Dataset.get_by_name(workspace, name=path)\n",
        "    df = df.to_pandas_dataframe()\n",
        "\n",
        "    return df\n"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1630358241179
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature Engineering\n",
        "# ------------------------------------------------\n",
        "# flag = 0 for train data, flag = 1 for test data\n",
        "# ------------------------------------------------\n",
        "\n",
        "def feature_engineering(X, flag = 0, training_cols = None):\n",
        "\n",
        "  X = X[['first_contact_date','origin','seller_id']]\n",
        "\n",
        "  #Convert date to year, month, day, quarter\n",
        "  X['year'] = pd.DatetimeIndex(X['first_contact_date']).year\n",
        "  X['month'] = pd.DatetimeIndex(X['first_contact_date']).month\n",
        "  X['day'] = pd.DatetimeIndex(X['first_contact_date']).day\n",
        "  X['quarter'] = X['month'].apply(lambda x:x//4)\n",
        "\n",
        "  #Drop contact date and seller id\n",
        "  X.drop(columns=['first_contact_date','seller_id'], axis=1, inplace=True)\n",
        "\n",
        "  X = pd.get_dummies(X, drop_first=True, prefix='', prefix_sep='')\n",
        "\n",
        "  if flag == 1:\n",
        "    X = X.T.reindex(training_cols).T.fillna(0)\n",
        "\n",
        "  return X, X.columns\n"
      ],
      "outputs": [],
      "execution_count": 4,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1630358241560
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_train_validation_data(closed_deals_path, market_lead_path):\n",
        "\n",
        "  closed_deals = load_data(closed_deals_path)\n",
        "  market_lead = load_data(market_lead_path)\n",
        "  \n",
        "  #Join the two datasets\n",
        "  mf = pd.merge(market_lead, closed_deals, left_on='mql_id', right_on='mql_id', how='left')\n",
        "\n",
        "  # Create target variable\n",
        "  mf['converted'] = mf[['seller_id']].where(mf[['seller_id']].isnull()==True, 1).fillna(0).astype(int)\n",
        "\n",
        "  X = mf.loc[:, mf.columns != 'converted']\n",
        "  y = mf.loc[:, ['converted']]\n",
        "\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)\n",
        "\n",
        "  X_train, training_cols = feature_engineering(X_train)\n",
        "\n",
        "  X_test, cols = feature_engineering(X_test, 1, training_cols)\n",
        "\n",
        "  return X_train, X_test, y_train, y_test, training_cols\n"
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1630358241814
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, X, y):\n",
        "  y_pred = model.predict(X.astype(np.int32))\n",
        "  cm = confusion_matrix(y, y_pred)\n",
        "  score = accuracy_score(y, y_pred)\n",
        "\n",
        "  return y_pred, cm, score\n"
      ],
      "outputs": [],
      "execution_count": 6,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1630358242055
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "closed_deals_path = 'olist_closed_deals' \n",
        "market_lead_path = 'olist_marketing_qualified_leads'\n",
        "\n",
        "X_train, X_test, y_train, y_test, training_cols = prepare_train_validation_data(closed_deals_path, market_lead_path)\n",
        "\n",
        "print(\"Done\")\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if sys.path[0] == '':\n",
            "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  del sys.path[0]\n",
            "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/pandas/core/frame.py:4117: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  errors=errors,\n"
          ]
        }
      ],
      "execution_count": 7,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1630358247737
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(X, y, params):\n",
        "\n",
        "\n",
        "  model = LogisticRegression(**params)\n",
        "  model.fit(X, y)\n",
        "\n",
        "  print(model)\n",
        "\n",
        "  return model\n"
      ],
      "outputs": [],
      "execution_count": 8,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1630358248023
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train model and log metrics with MLflow\n",
        "\n",
        "You'll train the model using the code below. Note that you are using MLflow autologging to track metrics and log model artefacts.\n",
        "\n",
        "You'll be using the [LogisticRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) classifier from the [SciKit Learn framework](https://scikit-learn.org/) to classify the data.\n",
        "\n",
        "**Note: The model training takes approximately 2 minutes to complete.**"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create the model\n",
        "import mlflow\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from azureml.core import Workspace\n",
        "from pprint import pprint\n",
        "\n",
        "# connect to your workspace\n",
        "ws = Workspace.from_config()\n",
        "\n",
        "# create experiment and start logging to a new run in the experiment\n",
        "experiment_name = \"olist_v1\"\n",
        "model_name = \"olist_sklearn_v1\"\n",
        "\n",
        "# set up MLflow to track the metrics\n",
        "mlflow.set_tracking_uri(ws.get_mlflow_tracking_uri())\n",
        "mlflow.set_experiment(experiment_name)\n",
        "mlflow.autolog()\n",
        "\n",
        "def fetch_logged_data(run_id):\n",
        "    client = mlflow.tracking.MlflowClient()\n",
        "    data = client.get_run(run_id).data\n",
        "    tags = {k: v for k, v in data.tags.items() if not k.startswith(\"mlflow.\")}\n",
        "    artifacts = [f.path for f in client.list_artifacts(run_id, \"model\")]\n",
        "    return data.params, data.metrics, tags, artifacts\n",
        "\n",
        "#params to train the model\n",
        "params = {'max_iter':10,'random_state':0,'penalty': 'l1','solver':'liblinear'}\n",
        "\n",
        "with mlflow.start_run() as run:\n",
        "    model = train_model(X_train, y_train, params)\n",
        "    \n",
        "    params, metrics, tags, artifacts = fetch_logged_data(run.info.run_id)\n",
        "\n",
        "    pprint(params)\n",
        "\n",
        "    pprint(metrics)\n",
        "\n",
        "    pprint(tags)\n",
        "\n",
        "    pprint(artifacts)\n",
        "\n",
        "print(\"Done\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2021/08/30 21:17:29 INFO mlflow.tracking.fluent: Autologging successfully enabled for sklearn.\n",
            "2021/08/30 21:17:29 INFO mlflow.pyspark.ml: No SparkSession detected. Autologging will log pyspark.ml models contained in the default allowlist. To specify a custom allowlist, initialize a SparkSession prior to calling mlflow.pyspark.ml.autolog() and specify the path to your allowlist file via the spark.mlflow.pysparkml.autolog.logModelAllowlistFile conf.\n",
            "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "2021/08/30 21:17:30 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/anaconda/envs/azureml_py36/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\"\n",
            "2021/08/30 21:17:31 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/anaconda/envs/azureml_py36/lib/python3.6/site-packages/mlflow/models/signature.py:129: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
            "                   intercept_scaling=1, l1_ratio=None, max_iter=10,\n",
            "                   multi_class='auto', n_jobs=None, penalty='l1',\n",
            "                   random_state=0, solver='liblinear', tol=0.0001, verbose=0,\n",
            "                   warm_start=False)\n",
            "{'C': '1.0',\n",
            " 'class_weight': 'None',\n",
            " 'dual': 'False',\n",
            " 'fit_intercept': 'True',\n",
            " 'intercept_scaling': '1',\n",
            " 'l1_ratio': 'None',\n",
            " 'max_iter': '10',\n",
            " 'multi_class': 'auto',\n",
            " 'n_jobs': 'None',\n",
            " 'penalty': 'l1',\n",
            " 'random_state': '0',\n",
            " 'solver': 'liblinear',\n",
            " 'tol': '0.0001',\n",
            " 'verbose': '0',\n",
            " 'warm_start': 'False'}\n",
            "{'training_accuracy_score': 0.8906666666666667,\n",
            " 'training_f1_score': 0.8391612599905971,\n",
            " 'training_log_loss': 0.3252851163807794,\n",
            " 'training_precision_score': 0.793287111111111,\n",
            " 'training_recall_score': 0.8906666666666667,\n",
            " 'training_roc_auc_score': 0.6777142646870893,\n",
            " 'training_score': 0.8906666666666667}\n",
            "{'estimator_class': 'sklearn.linear_model._logistic.LogisticRegression',\n",
            " 'estimator_name': 'LogisticRegression'}\n",
            "['model/MLmodel',\n",
            " 'model/conda.yaml',\n",
            " 'model/model.pkl',\n",
            " 'model/requirements.txt']\n",
            "Done\n"
          ]
        }
      ],
      "execution_count": 9,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1630358254318
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Version control of our models with the model registry\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "model_uri = \"runs:/{}/model\".format(run.info.run_id)\n",
        "\n",
        "model = mlflow.register_model(\n",
        "    model_uri,\n",
        "    model_name\n",
        ")\n",
        "time.sleep(10)\n",
        "current_version = model.version\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Registered model 'olist_sklearn_v1' already exists. Creating a new version of this model...\n",
            "2021/08/30 21:17:35 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation.                     Model name: olist_sklearn_v1, version 2\n",
            "Created version '2' of model 'olist_sklearn_v1'.\n"
          ]
        }
      ],
      "execution_count": 10,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1630358266078
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Validate current model on test data"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import mlflow\n",
        "import mlflow.pyfunc\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "\n",
        "\n",
        "model_version = current_version\n",
        "\n",
        "model = mlflow.pyfunc.load_model(\n",
        "    model_uri=f\"models:/{model_name}/{model_version}\"\n",
        ")\n",
        "\n",
        "\n",
        "pprint(evaluate(model,X_test, y_test))\n",
        "\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(array([0, 0, 0, ..., 0, 0, 0]),\n",
            " array([[1814,    0],\n",
            "       [ 186,    0]]),\n",
            " 0.907)\n"
          ]
        }
      ],
      "execution_count": 11,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1630358267146
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Find the best model"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "from mlflow.tracking.client import MlflowClient\n",
        "from mlflow.entities import ViewType\n",
        "\n",
        "experiment = MlflowClient().get_experiment_by_name(experiment_name)\n",
        "\n",
        "# pprint(experiment)\n",
        "experiment_ids = experiment.experiment_id\n",
        "\n",
        "#Reading Pandas Dataframe from mlflow\n",
        "runs= MlflowClient().search_runs(experiment_ids, run_view_type=ViewType.ALL)\n",
        "\n",
        "score = None\n",
        "run_id = 'NULL'\n",
        "best_run = None\n",
        "best_version = 0\n",
        "\n",
        "client = MlflowClient()\n",
        "\n",
        "for run in runs:\n",
        "    if 'training_roc_auc_score' in run.data.metrics.keys():\n",
        "        if(score == None or run.data.metrics['training_roc_auc_score'] > score):\n",
        "            try:\n",
        "                score = run.data.metrics['training_roc_auc_score']\n",
        "                if len(client.search_model_versions(f\"run_id ='{run.info.run_id}'\"))>0:\n",
        "                    best_run = run\n",
        "                    run_id = run.info.run_id\n",
        " \n",
        "            except:\n",
        "                print(\"Metric not found for run_id:\", run_id)\n",
        "\n",
        "print(\"Best training roc_auc_score: \",score)\n",
        "print(\"Run ID: \", run_id)\n",
        "\n",
        "for mv in client.search_model_versions(f\"run_id ='{run_id}'\"):\n",
        "    best_version = int(dict(mv)['version'])\n",
        "    pprint(best_version)\n",
        "\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best training roc_auc_score:  0.6777142646870893\n",
            "Run ID:  ee9745bd-78f0-40dd-b065-fcfd557cd45a\n",
            "1\n"
          ]
        }
      ],
      "execution_count": 12,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1630358267495
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Push the best version to staging"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Archive existing model in staging\n",
        "max_version = 0\n",
        "for mv in client.search_model_versions(f\"name ='{model_name}'\"):\n",
        "    try:\n",
        "        current_version = int(dict(mv)['version'])\n",
        "        if current_version!= best_version and int(dict(mv)['current_stage']) == 'staging':\n",
        "            client.transition_model_version_stage(\n",
        "                name=model_name,\n",
        "                version=current_version,\n",
        "                stage=\"archived\")\n",
        "    except:\n",
        "        print(\"Error with model\")    \n",
        "\n",
        "# Transition best model to staging\n",
        "client = mlflow.tracking.MlflowClient()\n",
        "client.transition_model_version_stage(\n",
        "    name=model_name,\n",
        "    version=best_version,\n",
        "    stage=\"staging\")    \n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error with model\n"
          ]
        },
        {
          "output_type": "execute_result",
          "execution_count": 13,
          "data": {
            "text/plain": "<ModelVersion: creation_timestamp=1630354954381, current_stage='staging', description='', last_updated_timestamp=1630358267642, name='olist_sklearn_v1', run_id='ee9745bd-78f0-40dd-b065-fcfd557cd45a', run_link='', source='azureml://experiments/olist_v1/runs/ee9745bd-78f0-40dd-b065-fcfd557cd45a/artifacts/model', status='READY', status_message='', tags={}, user_id='', version='1'>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 13,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1630358268260
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Deploy the model for real-time inference\n",
        "In this section you learn how to deploy a model so that an application can consume (inference) the model over REST.\n",
        "\n",
        "### Create deployment configuration\n",
        "The code cell gets a _curated environment_, which specifies all the dependencies required to host the model (for example, the packages like scikit-learn). Also, you create a _deployment configuration_, which specifies the amount of compute required to host the model. In this case, the compute will have 1CPU and 1GB memory."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create environment for the deploy\n",
        "from azureml.core.environment import Environment\n",
        "from azureml.core.conda_dependencies import CondaDependencies\n",
        "from azureml.core.webservice import AciWebservice\n",
        "\n",
        "# get a curated environment\n",
        "env = Environment.get(\n",
        "    workspace=ws, \n",
        "    name=\"AzureML-sklearn-0.24.1-ubuntu18.04-py37-cpu-inference\",\n",
        "    version=1\n",
        ")\n",
        "env.inferencing_stack_version='latest'\n",
        "\n",
        "# create deployment config i.e. compute resources\n",
        "aciconfig = AciWebservice.deploy_configuration(\n",
        "    cpu_cores=1,\n",
        "    memory_gb=1,\n",
        "    tags={\n",
        "            \"data\": \"https://www.kaggle.com/olistbr/marketing-funnel-olist\",\n",
        "            \"method\": \"predict\"\n",
        "        },\n",
        "    description=\"Predict whether a lead will be converted or not\",\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 14,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1630358268651
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Deploy model\n",
        "\n",
        "This next code cell deploys the model to Azure Container Instance (ACI).\n",
        "\n",
        "**Note: The deployment takes approximately 3 minutes to complete.**"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "import uuid\n",
        "from azureml.core.model import InferenceConfig\n",
        "from azureml.core.environment import Environment\n",
        "from azureml.core.model import Model\n",
        "\n",
        "# get the registered model\n",
        "model = Model(ws, model_name, version = best_version)\n",
        "\n",
        "# create an inference config i.e. the scoring script and environment\n",
        "inference_config = InferenceConfig(entry_script=\"score.py\", environment=env)\n",
        "\n",
        "pprint(inference_config)\n",
        "\n",
        "# deploy the service\n",
        "service_name = \"sklearn-olist-lr-\" + str(uuid.uuid4())[:4]\n",
        "service = Model.deploy(\n",
        "    workspace=ws,\n",
        "    name=service_name,\n",
        "    models=[model],\n",
        "    inference_config=inference_config,\n",
        "    deployment_config=aciconfig,\n",
        ")\n",
        "\n",
        "service.wait_for_deployment(show_output=True)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "InferenceConfig(entry_script=score.py, runtime=None, conda_file=None, extra_docker_file_steps=None, source_directory=None, enable_gpu=None, base_image=None, base_image_registry=<azureml.core.container_registry.ContainerRegistry object at 0x7f697680ceb8>)\n",
            "Tips: You can try get_logs(): https://aka.ms/debugimage#dockerlog or local deployment: https://aka.ms/debugimage#debug-locally to debug if deployment takes longer than 10 minutes.\n",
            "Running\n",
            "2021-08-30 21:17:55+00:00 Creating Container Registry if not exists.\n",
            "2021-08-30 21:17:55+00:00 Registering the environment.\n",
            "2021-08-30 21:17:56+00:00 Use the existing image.\n",
            "2021-08-30 21:17:56+00:00 Generating deployment configuration.\n",
            "2021-08-30 21:17:57+00:00 Submitting deployment to compute.\n",
            "2021-08-30 21:18:01+00:00 Checking the status of deployment sklearn-olist-lr-e0ff..\n",
            "2021-08-30 21:19:09+00:00 Checking the status of inference endpoint sklearn-olist-lr-e0ff.\n",
            "Succeeded\n",
            "ACI service creation operation finished, operation \"Succeeded\"\n",
            "CPU times: user 309 ms, sys: 72.2 ms, total: 381 ms\n",
            "Wall time: 1min 24s\n"
          ]
        }
      ],
      "execution_count": 15,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The [*scoring script*](score.py) file referenced in the code above can be found in the same folder as this notebook, and has two functions:\n",
        "\n",
        "1. an `init` function that executes once when the service starts - in this function you normally get the model from the registry and set global variables\n",
        "1. a `run(data)` function that executes each time a call is made to the service. In this function, you normally format the input data, run a prediction, and output the predicted result.\n",
        "\n",
        "### View Endpoint\n",
        "Once the model has been successfully deployed, you can view the endpoint by navigating to __Endpoints__ in the left-hand menu in Azure Machine Learning Studio. You will be able to see the state of the endpoint (healthy/unhealthy), logs, and consume (how applications can consume the model)."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test the model service\n",
        "\n",
        "You can test the model by sending a raw HTTP request to test the web service. "
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# send raw HTTP request to test the web service.\n",
        "import requests\n",
        "\n",
        "# send a random row from the test set to score\n",
        "random_index = np.random.randint(0, len(X_test) - 1)\n",
        "input_data = '{\"data\": [' + str(list(X_test.iloc[random_index,])) + \"]}\"\n",
        "\n",
        "print(\"Random_index: \", random_index)\n",
        "pprint(input_data)\n",
        "\n",
        "headers = {\"Content-Type\": \"application/json\"}\n",
        "\n",
        "resp = requests.post(service.scoring_uri, input_data, headers=headers)\n",
        "\n",
        "print(\"POST to url\", service.scoring_uri)\n",
        "print(\"label:\", y_test.iloc[random_index,])\n",
        "print(\"prediction:\", resp.text)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random_index:  1539\n",
            "'{\"data\": [[2018, 2, 23, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}'\n",
            "POST to url http://dd392b2e-ab0f-44d8-a352-a8a74627d93b.eastus2.azurecontainer.io/score\n",
            "label: converted    0\n",
            "Name: 5587, dtype: int64\n",
            "prediction: [0]\n"
          ]
        }
      ],
      "execution_count": 16,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1630358353445
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clean up resources\n",
        "\n",
        "If you're not going to continue to use this model, delete the Model service using:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Delete all web services\n",
        "from azureml.core import Webservice\n",
        "for webservice in Webservice.list(ws):\n",
        "    print('name:', webservice.name)\n",
        "    Webservice(ws, name = webservice.name).delete()\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "name: sklearn-olist-lr-e0ff\n"
          ]
        }
      ],
      "execution_count": 17,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1630358358063
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "authors": [
      {
        "name": "cewidste"
      }
    ],
    "kernelspec": {
      "name": "python3-azureml",
      "language": "python",
      "display_name": "Python 3.6 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "notice": "Copyright (c) Microsoft Corporation. All rights reserved. Licensed under the MIT License.",
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "categories": [
      "tutorials",
      "compute-instance-quickstarts"
    ],
    "kernel_info": {
      "name": "python3-azureml"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}